{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34a4b245e795"
   },
   "source": [
    "# Feed the Sleuth: find 2nd/3rd/... nearest neighbor in scale  \n",
    "\n",
    "__with Approximate Nearest Neighbor in Anisotropic Vector Quantization, Shallow Tree + Asymmetric Hashing, and Sentence Transformer__\n",
    "\n",
    "## 0. Imperative: binge watch Tom and Jerry, but with different plots \n",
    "\n",
    "We are binge watching Tom and Jerry, and want to continue with similar-but-not-the-exactly-the-same episodes. \n",
    "\n",
    "For example, in one episode, Tom is dreaming about catching Jerry in the sleep, whereas in another episode, Tom is really chasing down Jerry (and not in the sleep-walking sense). \n",
    "\n",
    "And back to real-life situations ... \n",
    "\n",
    "In the case of __renter's insurance__, how can we tell __contract 1 lightly touches on plumbing, whereas contract 2 includes substantial clauses__?\n",
    "\n",
    "__More generally, can we feed months/years of software/building/legal contacts, to discover (subtle) changes, i.e. COVID-19 could break up the contracts?__\n",
    "\n",
    "In other words, can we __feed colossal amount of documents without domain knowledge/supervised learning, so as to surface and drive the adoption for Document/Label Sleuth/other AI/ML/NLP tools__?\n",
    "\n",
    "\n",
    "### 0.1. Solution: find close-but-not-the-exactly-same clues, in scale\n",
    "\n",
    "One potential way is to be able to \n",
    "1. Measure the distance of vector/embeddings, i.e., think of Cosine Similiarities in extremely high yet sparse representations\n",
    "2. Find the __2nd/3rd/4th.. closest distance, but not the closest-distanced nor the precisely-matched one__ \n",
    "3. And __do so in-scale__\n",
    "\n",
    "\n",
    "### 0.2. Approximate Nearest Neighbor (ANN) with Anisotropic Vector Quantization, Shallow Tree + Asymmetric Hashing\n",
    "\n",
    "Google's Approximate Nearest Neighbor (ANN) Index is a high scale, low latency solution, to find similar vectors (or more specifically \"embeddings\") for a large corpus. \n",
    "\n",
    "The highlight is \"Anisotropic Vector Quantization\" [Approximate Nearest Neighbor (ANN) technology](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html). \n",
    "\n",
    "### 0.3. Vector/embedding with Setence Transfomer/sentence-t5-base \n",
    "\n",
    "To build the vector/embedding, we are using Setence Transfomer/sentence-t5-base from Hugging Face\n",
    "https://huggingface.co/blog/sentence-transformers-in-the-hub\n",
    "\n",
    "\n",
    "### 0.4. Distance measure of 'The cat likes to sleep in the sun' to 9 other sentences\n",
    "\n",
    "Let's say that, we have summarized a Tom and Jerry episode into the one-liner of \n",
    "\n",
    "'The cat likes to sleep in the sun'.\n",
    "\n",
    "Meanwhile, we have summarized 9 other random TV-shows into 9 one-liners as follows:\n",
    "1. I spent the day at the medical facility.\n",
    "2. That a cultured medical genius found her inspiring was beyond flattering.\n",
    "3. She drew nearer, eyes sweeping over the medical equipment in the room.\n",
    "4. I did not ask the American Medical Association their opinion of this arrangement.\n",
    "5. I think the cat wants dessert!\n",
    "6. Im in no mood to watch a cat fight tonight.\n",
    "7. The cat would like to eat the mouse.\n",
    "8. A large grey cat was asleep on a rocking chair.\n",
    "9. The pilot was able to land the airplane\n",
    "\n",
    "### 0.5. Result \n",
    "\n",
    "You will see in the following that for the sentence of\n",
    "'The cat likes to sleep in the sun'.\n",
    "\n",
    "The closest sentences would be:\n",
    "1. A large grey cat was asleep on a rocking chair.\n",
    "2. I think the cat wants dessert!\n",
    "3. The cat would like to eat the mouse.\n",
    "4. Im in no mood to watch a cat fight tonight.\n",
    "5. The pilot was able to land the airplane\n",
    "\n",
    "Pretty good, right?\n",
    "\n",
    "### 0.6. Continue watching episodes 2 and 3 \n",
    "\n",
    "Based on above, we will toss away show 1 because it is roughly the same, and show 4/5 since they are not our interests, leaving with episodes 2/3:\n",
    "\n",
    "2. I think the cat wants dessert!\n",
    "3. The cat would like to eat the mouse.\n",
    "\n",
    "Now we can continue binge watching!\n",
    "\n",
    "\n",
    "### 0.7 Specific steps\n",
    "1. Prep environment/var\n",
    "2. Create vector/embedding with sentence-transformers\n",
    "3. Create ANN Index and Brute Force Index\n",
    "4. Create an IndexEndpoint with VPC Network\n",
    "5. Deploy ANN Index\n",
    "6. Perform online query\n",
    "\n",
    "### 0.8 To-do\n",
    "\n",
    "Test cases, algorithms (sorting), document/contracts  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irSMQn6gZ19l"
   },
   "source": [
    "## 1. Prepare environment and variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "### 1.1 Get GCP's project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "beb72f394541"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID:  me-ann1-370514\n"
     ]
    }
   ],
   "source": [
    "shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = shell_output[0]\n",
    "print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_NUMBER: 25661841074\n"
     ]
    }
   ],
   "source": [
    "PROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
    "#print(\"PROJECT_NUMBER: {}\".format(PROJECT_NUMBER))\n",
    "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
    "print(\"PROJECT_NUMBER: {}\".format(PROJECT_NUMBER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### 1.2 Create a Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7tcBkCDI1_M"
   },
   "source": [
    "Set Random ID (optional), to avoid name collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HpIK91y1IzDr"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "RANDOM_ID = \"\".join(random.choices(string.ascii_lowercase + string.digits, k=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://me-ann1-370514-aip-og0kjvbz us-central1\n"
     ]
    }
   ],
   "source": [
    "REGION = \"us-central1\"\n",
    "BUCKET_URI = \"gs://\" + PROJECT_ID + \"-aip-\" + RANDOM_ID\n",
    "\n",
    "print(BUCKET_URI, REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://me-ann1-370514-aip-og0kjvbz/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucvCsknMCims"
   },
   "source": [
    "Check the bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vhOb7YnwClBb"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## 2. Create vector/embedding with sentence-transformers\n",
    "\n",
    "### 2.1 Sentence Transformers and sentence-t5-base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.64.1)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.13.0-cp37-cp37m-manylinux1_x86_64.whl (890.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.2/890.2 MB\u001b[0m \u001b[31m635.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.14.0-cp37-cp37m-manylinux1_x86_64.whl (24.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.3)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.11.4)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (59.8.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (0.37.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.1/757.1 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=b23bd14dae1fc3b23cb926520ec93fb9435e64dc79b03a6cb4523cecbd7c7eb4\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/83/71/2b/40d17d21937fed496fb99145227eca8f20b4891240ff60c86f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, regex, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, filelock, nvidia-cudnn-cu11, huggingface-hub, transformers, torch, nltk, torchvision, sentence-transformers\n",
      "Successfully installed filelock-3.8.0 huggingface-hub-0.11.1 nltk-3.7 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 regex-2022.10.31 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 torch-1.13.0 torchvision-0.14.0 transformers-4.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7b547e3ba742f78b3dce9d13d38687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b3a4eeba0c4d7b82cfad339098eb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8ba916c2a1454da1fe256a8f43f12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/115 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0f88bceaf84edc9153131f3851cdb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61ddf93fd884e649a7c505b538ec014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54bd9a1bce44d44a373a1e3008bd13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14fbbe40b724c7699241501b45fd70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a0a85c852343659283543ed86c89ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a240e2b6884142856196cbcae48ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/74.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5292e80467544c66ad92dc5113af3c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/198 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d0e769e7f04807bfcb988918e09d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/219M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dbabf9588d48098309b3452e35e84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8acf915941834c4c9eea4f83dbad4604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7414764eac6c4e18bfb1173decefc4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5069608f35ee474c926bc0a7d6728364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98fc42cc2ce84a7e9fae83d01f166897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae95cb6a849145efa8773f1914e0fe18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-t5-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create sentences, embeddings, then save into JSON for upload to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['I spent the day at the medical facility.', #0\n",
    "            'That a cultured medical genius found her inspiring was beyond flattering.', #1\n",
    "            'She drew nearer, eyes sweeping over the medical equipment in the room.', #2\n",
    "            'I did not ask the American Medical Association their opinion of this arrangement.', #3\n",
    "            'I think the cat wants dessert!', #4\n",
    "            'Im in no mood to watch a cat fight tonight.', #5\n",
    "            'The cat would like to eat the mouse.', #6\n",
    "            'A large grey cat was asleep on a rocking chair.', # 7\n",
    "            'The pilot was able to land the airplane'] #8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.encode(sentences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 768)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"init_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, \"w\") as f:\n",
    "    for i in range(len(sentences)):\n",
    "        f.write('{\"id\":\"' + str(i) + '\",')\n",
    "        f.write('\"embedding\":[' + \",\".join(str(x) for x in embedding[i]) + \"]}\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuVl8DrWG8NS"
   },
   "source": [
    "### 2.3 Upload JSON data to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://me-ann1-370514-aip-og0kjvbz/matching_engine/initial/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/matching_engine/initial/\"\n",
    "EMBEDDINGS_INITIAL_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3PgsA_vbI8Vg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Copying file://init_data.json [Content-Type=application/json]...\n",
      "/ [1 files][ 83.6 KiB/ 83.6 KiB]                                                \n",
      "Operation completed over 1 objects/83.6 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp init_data.json {EMBEDDINGS_INITIAL_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mglUPwHpJH98"
   },
   "source": [
    "## 3. Create Indexes\n",
    "\n",
    "### 3.1  Define constants for Vertex AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Y4zooldkGoM4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qiIg9b5zJLi1"
   },
   "outputs": [],
   "source": [
    "DIMENSIONS = 768\n",
    "DISPLAY_NAME = \"tree_ah_st5\"\n",
    "ANN_COUNT=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svLYiDf0OD2G"
   },
   "source": [
    "### 3.2 Create ANN index with configurations (Shallow tree + Asymmetric Hashing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xzY7TpUSJcTV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/25661841074/locations/us-central1/indexes/1029503523412246528/operations/1538633825762934784\n",
      "MatchingEngineIndex created. Resource name: projects/25661841074/locations/us-central1/indexes/1029503523412246528\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/25661841074/locations/us-central1/indexes/1029503523412246528')\n"
     ]
    }
   ],
   "source": [
    "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
    "    dimensions=DIMENSIONS,\n",
    "    approximate_neighbors_count=ANN_COUNT,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    leaf_node_embedding_count=500,\n",
    "    leaf_nodes_to_search_percent=7,\n",
    "    description=\"Sentence-t5-base ANN index\",\n",
    "    labels={\"label_name\": \"label_value\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f1a9fbecabb"
   },
   "source": [
    "### 3.3 Get the resource name, to retrieve it later existing MatchingEngineIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "17jrQi501QyX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/25661841074/locations/us-central1/indexes/1029503523412246528'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
    "INDEX_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "1ddb70647d98"
   },
   "outputs": [],
   "source": [
    "# tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV2xjAnDDObD"
   },
   "source": [
    "## 4. Create an IndexEndpoint (with VPC Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "BpZQoJyxDlbO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/25661841074/global/networks/vpc1'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VPC_NETWORK = \"vpc1\"\n",
    "VPC_NETWORK_FULL = \"projects/{}/global/networks/{}\".format(PROJECT_NUMBER, VPC_NETWORK)\n",
    "VPC_NETWORK_FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "QuARXzJVGyQX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/25661841074/locations/us-central1/indexEndpoints/6162762673684480000/operations/3099131096646811648\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/25661841074/locations/us-central1/indexEndpoints/6162762673684480000\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/25661841074/locations/us-central1/indexEndpoints/6162762673684480000')\n"
     ]
    }
   ],
   "source": [
    "index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=\"ANN_index_endpoint\",\n",
    "    description=\"Sentence-t5-base ANN IndexEndpoint\",\n",
    "    network=VPC_NETWORK_FULL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the resource name, to retrieve it later with MatchingEngineIndexEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PJ3bcZqi-cfM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/25661841074/locations/us-central1/indexEndpoints/6162762673684480000'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_ENDPOINT_NAME = index_endpoint.resource_name\n",
    "INDEX_ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ew1UgcIIiJG"
   },
   "source": [
    "## 5. Deploy ANN Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "nLOYTGygIlMK"
   },
   "outputs": [],
   "source": [
    "DEPLOYED_INDEX_ID = f\"ANN_ST5_deployed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "_uK4WOgqN1NG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/25661841074/locations/us-central1/indexEndpoints/6162762673684480000\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/25661841074/locations/us-central1/indexEndpoints/6162762673684480000/operations/1275173247561760768\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/25661841074/locations/us-central1/indexEndpoints/6162762673684480000\n"
     ]
    }
   ],
   "source": [
    "index_endpoint = index_endpoint.deploy_index(\n",
    "    index=tree_ah_index, deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    min_replica_count=1, max_replica_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"ANN_ST5_deployed\"\n",
       "index: \"projects/25661841074/locations/us-central1/indexes/1029503523412246528\"\n",
       "create_time {\n",
       "  seconds: 1670085001\n",
       "  nanos: 825895000\n",
       "}\n",
       "private_endpoints {\n",
       "  match_grpc_address: \"10.63.96.5\"\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1670085884\n",
       "  nanos: 985000\n",
       "}\n",
       "automatic_resources {\n",
       "  min_replica_count: 1\n",
       "  max_replica_count: 1\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LCGvBNvBd8D"
   },
   "source": [
    "## 6. Create Online Queries\n",
    "\n",
    "Query against deployed index through online querying gRPC API (Match service) within virtual machine instances from the same region.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of nearest neighbors to be retrieved from database for each query.\n",
    "NUM_NEIGHBOURS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ['The cat likes to sleep in the sun']\n",
    "QUERY = model.encode(sentence)\n",
    "type(QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index_endpoint.match(\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID, queries=QUERY, num_neighbors=NUM_NEIGHBOURS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='7', distance=0.8463100790977478),\n",
       "  MatchNeighbor(id='4', distance=0.8144865036010742),\n",
       "  MatchNeighbor(id='6', distance=0.7567464709281921),\n",
       "  MatchNeighbor(id='5', distance=0.6951133608818054),\n",
       "  MatchNeighbor(id='8', distance=0.6735643148422241),\n",
       "  MatchNeighbor(id='0', distance=0.6379110217094421),\n",
       "  MatchNeighbor(id='1', distance=0.607258677482605),\n",
       "  MatchNeighbor(id='2', distance=0.5947748422622681),\n",
       "  MatchNeighbor(id='3', distance=0.5791853666305542)]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sdk_matching_engine_for_indexing.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
